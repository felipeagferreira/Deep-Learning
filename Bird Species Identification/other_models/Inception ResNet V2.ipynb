{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Inception ResNet V2.ipynb","provenance":[{"file_id":"1pMsUuP74gX09RDPrwnqP8hyHh59Lzy6X","timestamp":1617251110424},{"file_id":"1XnmQHg5_0Tt444mNeF1rf8NLzrMSa8m_","timestamp":1617161063556},{"file_id":"1ptDH667jGyIC-sSY4Bdpxdim94KpxxCb","timestamp":1617066177015},{"file_id":"1UlU66Lp3u0eJv-92NyrN9czMDqD60sez","timestamp":1617051266567},{"file_id":"1cVlErzQ85tJVIRNQQ61SwhZoIZz8g0IK","timestamp":1616894983117}],"collapsed_sections":["5Xv4z3BT5c7W"],"toc_visible":true,"machine_shape":"hm","authorship_tag":"ABX9TyORzheLDymOQvkTNP0KlRPS"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"YrZjRCS92_03","executionInfo":{"status":"ok","timestamp":1617312703542,"user_tz":180,"elapsed":2232,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["import logging\n","import os\n","import warnings\n","\n","import matplotlib.pyplot as plt\n","import matplotlib.style as style\n","import numpy as np\n","import pandas as pd\n","import seaborn as sns\n","import tensorflow as tf\n","import tensorflow_hub as hub\n","\n","from datetime import datetime\n","from keras.preprocessing import image\n","from PIL import Image\n","from sklearn.preprocessing import MultiLabelBinarizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.calibration import calibration_curve\n","from tensorflow.keras import layers\n","\n","warnings.filterwarnings('ignore')\n","logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)"],"execution_count":1,"outputs":[]},{"cell_type":"code","metadata":{"id":"THJbanWt3xxT","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617312706188,"user_tz":180,"elapsed":937,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"84a061db-bb2e-4d81-a43e-a4f2ddf6e1aa"},"source":["from google.colab import drive\n","drive.mount('/content/drive')\n","#drive.flush_and_unmount()"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0Rr7lQ683xtu","executionInfo":{"status":"ok","timestamp":1617312709563,"user_tz":180,"elapsed":939,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["datasetdir = '/content/drive/MyDrive/MMAI 894 - DEEP LEARNING/TEAM PROJECT/images_scaled'\n","os.chdir(datasetdir)"],"execution_count":3,"outputs":[]},{"cell_type":"code","metadata":{"id":"NuZw_1tL3xsA","executionInfo":{"status":"ok","timestamp":1617312724860,"user_tz":180,"elapsed":8758,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["# Load file locations\n","df_info = pd.read_excel('/content/drive/MyDrive/MMAI 894 - DEEP LEARNING/TEAM PROJECT/dataset_information.xlsx', sheet_name = 'images.txt')\n","\n","#Load class information\n","df_classes = pd.read_excel('/content/drive/MyDrive/MMAI 894 - DEEP LEARNING/TEAM PROJECT/dataset_information.xlsx', sheet_name = 'classes.txt')"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"GTkswldw3xpq","executionInfo":{"status":"ok","timestamp":1617312733737,"user_tz":180,"elapsed":957,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["#Split the class and image name\n","df_image = df_info.join(df_info['image_location'].str.split('/',expand=True).rename(columns={0:'class_id',1:'image_name'})) "],"execution_count":5,"outputs":[]},{"cell_type":"code","metadata":{"id":"6anOAnwm3xnH","executionInfo":{"status":"ok","timestamp":1617312736389,"user_tz":180,"elapsed":949,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["#Convert the string column to INT to chop leading zeroes\n","df_image['class_id'] = df_image['class_id'].astype(int)"],"execution_count":6,"outputs":[]},{"cell_type":"code","metadata":{"id":"WcsVkhZN3xk8","executionInfo":{"status":"ok","timestamp":1617312739440,"user_tz":180,"elapsed":1452,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["#Join the information and class dataframe \n","df_bird = pd.merge(df_image, df_classes, left_on='class_id', right_on='child_class_id', how='left').drop('child_class_id', axis=1)"],"execution_count":7,"outputs":[]},{"cell_type":"code","metadata":{"id":"YqNZWY823xit","executionInfo":{"status":"ok","timestamp":1617312743830,"user_tz":180,"elapsed":1019,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["#Find the count of bird class in case only specific classes need to be to the model\n","DF_classcounts = df_bird.groupby(['class_id'])['class_id'].count().reset_index(name='count').sort_values(['count'], ascending=False) "],"execution_count":8,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ydZ79bpGi-I1","executionInfo":{"status":"ok","timestamp":1617311863291,"user_tz":180,"elapsed":946,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"e759a04c-8b07-479e-ed01-1855ecdf4b3e"},"source":["DF_classcounts['count'].values"],"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n","       120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n","       120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n","       120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n","       120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n","       120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120, 120,\n","       120, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119, 119,\n","       119, 119, 119, 119, 119, 119, 118, 118, 118, 118, 118, 118, 118,\n","       118, 118, 118, 118, 118, 118, 118, 117, 117, 117, 117, 117, 117,\n","       117, 117, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116, 116,\n","       116, 116, 116, 116, 115, 115, 115, 115, 114, 114, 114, 114, 113,\n","       113, 113, 113, 113, 113, 113, 113, 113, 112, 112, 112, 112, 112,\n","       111, 111, 111, 111, 111, 111, 111, 110, 110, 110, 110, 110, 109,\n","       109, 109, 109, 109, 109, 109, 109, 109, 109, 109, 108, 108, 108,\n","       108, 108, 108, 108, 108, 107, 107, 107, 106, 106, 106, 106, 106,\n","       106, 106, 105, 105, 105, 105, 105, 104, 104, 104, 104, 104, 103,\n","       103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 103, 102, 102,\n","       102, 101, 101, 101, 101, 101, 101, 101, 100, 100,  99,  99,  99,\n","        99,  99,  98,  98,  98,  98,  98,  98,  98,  98,  98,  98,  97,\n","        97,  97,  97,  97,  96,  96,  96,  96,  96,  95,  95,  95,  94,\n","        94,  94,  94,  94,  94,  93,  93,  93,  93,  93,  93,  92,  92,\n","        92,  92,  92,  91,  91,  91,  90,  90,  90,  90,  89,  89,  89,\n","        89,  89,  88,  88,  88,  88,  87,  87,  87,  87,  87,  87,  87,\n","        86,  86,  86,  86,  86,  86,  86,  85,  85,  85,  84,  84,  83,\n","        83,  83,  83,  82,  82,  82,  82,  82,  82,  82,  81,  81,  81,\n","        81,  81,  80,  80,  80,  80,  80,  80,  80,  80,  79,  79,  79,\n","        78,  78,  78,  78,  78,  78,  77,  77,  77,  77,  77,  77,  77,\n","        76,  76,  76,  76,  76,  76,  76,  76,  75,  75,  75,  75,  75,\n","        75,  75,  75,  75,  75,  74,  74,  74,  74,  74,  74,  74,  73,\n","        73,  73,  72,  72,  72,  72,  72,  72,  72,  72,  72,  71,  71,\n","        71,  71,  71,  70,  70,  70,  70,  70,  70,  70,  70,  69,  69,\n","        69,  67,  67,  67,  67,  67,  66,  66,  66,  66,  66,  66,  66,\n","        66,  66,  65,  65,  65,  65,  65,  65,  65,  65,  64,  64,  64,\n","        64,  64,  64,  64,  64,  64,  63,  63,  63,  63,  63,  62,  62,\n","        62,  62,  62,  61,  61,  61,  61,  60,  60,  60,  60,  59,  59,\n","        59,  59,  59,  59,  58,  58,  58,  58,  57,  57,  57,  56,  56,\n","        55,  55,  55,  55,  55,  54,  54,  54,  54,  54,  54,  54,  53,\n","        53,  53,  53,  53,  53,  52,  51,  51,  50,  50,  50,  50,  49,\n","        49,  49,  49,  48,  48,  48,  48,  47,  47,  47,  47,  47,  47,\n","        46,  46,  46,  45,  45,  45,  44,  44,  44,  44,  44,  42,  42,\n","        42,  41,  41,  41,  41,  40,  39,  39,  39,  39,  37,  37,  37,\n","        36,  36,  35,  35,  34,  33,  33,  32,  32,  32,  31,  31,  31,\n","        31,  30,  28,  27,  25,  24,  23,  21,  13])"]},"metadata":{"tags":[]},"execution_count":9}]},{"cell_type":"markdown","metadata":{"id":"h0Bgd85hmaU3"},"source":["## **Target Variables here: all classes with (Number of images) >= 60. Total 453 classes with 43955 images.**"]},{"cell_type":"code","metadata":{"id":"cLp9fWFHLK4S","executionInfo":{"status":"ok","timestamp":1617312749554,"user_tz":180,"elapsed":918,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["#Selected only specific labels\n","target_class = DF_classcounts[(DF_classcounts['count']>=60) & (DF_classcounts['count']<=120)]['class_id'].values\n","\n","df_bird['FILTERED_LABEL'] = (df_bird.class_id.isin(target_class)).astype('int')"],"execution_count":9,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"RY7tY7kFOhmG","executionInfo":{"status":"ok","timestamp":1617312752411,"user_tz":180,"elapsed":963,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"37902385-0a0a-41d3-a5a7-d8d191c4407a"},"source":["DF_classcounts[(DF_classcounts['count']>=60) & (DF_classcounts['count']<=120)]['count'].sum()"],"execution_count":10,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43955"]},"metadata":{"tags":[]},"execution_count":10}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"xHHiPk5eN4ew","executionInfo":{"status":"ok","timestamp":1617311875383,"user_tz":180,"elapsed":997,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"da2bcb13-f61f-4fd0-94c5-db7b6f34179f"},"source":["len(target_class)"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["453"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"H8htDGjQ3xd-","executionInfo":{"status":"ok","timestamp":1617312757135,"user_tz":180,"elapsed":923,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["df_target =  df_bird[df_bird['FILTERED_LABEL']==1]"],"execution_count":11,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-RkFUvUw-U-1","executionInfo":{"status":"ok","timestamp":1617311881828,"user_tz":180,"elapsed":1019,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"30f450ac-801d-435a-9f2d-848a8b6f1b15"},"source":["len(df_target)"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43955"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"unr-pCro3xbf","executionInfo":{"status":"ok","timestamp":1617312760213,"user_tz":180,"elapsed":963,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["# Move 'class_id' and 'image_location' into string type features \n","df_target['class_id'] = df_target['class_id'].astype(str)\n","df_target['image_location'] = df_target['image_location'].astype(str)"],"execution_count":12,"outputs":[]},{"cell_type":"code","metadata":{"id":"sMISw75a5tYp","executionInfo":{"status":"ok","timestamp":1617312763816,"user_tz":180,"elapsed":922,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["datasetdir = '/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled'\n","os.chdir(datasetdir)"],"execution_count":13,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"omBJkuYwBm3T"},"source":["**Split the data into train set 60%, validation set 15% and a test set 25%.**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"CndRVAdTDWIg","executionInfo":{"status":"ok","timestamp":1617312767403,"user_tz":180,"elapsed":942,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"9a5ba710-6147-49e9-dbbf-f1f9d0902140"},"source":["X_train, X_test, y_train, y_test = train_test_split(df_target['image_location'], df_target['class_id'], test_size=0.25, random_state=44)\n","X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=1/5, train_size=4/5, random_state=44)\n","\n","print(\"Number of posters for training: \", len(X_train))\n","print(\"Number of posters for validation: \", len(X_val))\n","print(\"Number of posters for training: \", len(X_test))"],"execution_count":14,"outputs":[{"output_type":"stream","text":["Number of posters for training:  26372\n","Number of posters for validation:  6594\n","Number of posters for training:  10989\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ODCFUJNI5tVK","executionInfo":{"status":"ok","timestamp":1617303192301,"user_tz":180,"elapsed":16038,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"120573dc-8d68-47dc-aeaf-d1aeb153274b"},"source":["len(X_train) + len(X_val) + len(X_test)"],"execution_count":18,"outputs":[{"output_type":"execute_result","data":{"text/plain":["43955"]},"metadata":{"tags":[]},"execution_count":18}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LF71kHUERToj","executionInfo":{"status":"ok","timestamp":1617303192301,"user_tz":180,"elapsed":16032,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"aa09191a-9cf9-4c9f-e538-19756648b652"},"source":["len(X_train)/len(df_target)"],"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.5999772494596747"]},"metadata":{"tags":[]},"execution_count":19}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"0IcImnQcRaGl","executionInfo":{"status":"ok","timestamp":1617303192302,"user_tz":180,"elapsed":16028,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"328e0748-b6cc-4637-ed88-d411d00fd55a"},"source":["len(X_val)/len(df_target)"],"execution_count":20,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.150017062905244"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PuzLItffRaV6","executionInfo":{"status":"ok","timestamp":1617303192302,"user_tz":180,"elapsed":16022,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"9631b295-184e-48f1-bcc5-302f3e77121d"},"source":["len(X_test)/len(df_target)"],"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["0.25000568763508135"]},"metadata":{"tags":[]},"execution_count":21}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"lvh8Lgvq5tT8","executionInfo":{"status":"ok","timestamp":1617312774637,"user_tz":180,"elapsed":1286,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"c0857f7c-2b14-452b-cceb-7b7392877f8c"},"source":["X_train = [os.path.join('/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/', str(f)) for f in X_train]\n","X_val = [os.path.join('/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/', str(f)) for f in X_val]\n","#X_test = [os.path.join('/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/', str(f)) for f in X_train]\n","X_train[:5]"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/0831/c387c0d6fa14497aaaf1ff3443154e5a.jpg',\n"," '/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/0613/5e26b456cdda49c1ba8d70069008d833.jpg',\n"," '/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/0767/931ee5a595d9438fbd8571024045713e.jpg',\n"," '/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/0914/5ec283f8edeb4abb89307c45dda2ac41.jpg',\n"," '/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/0395/bcb091b457b944a193a5f5d5c2201c35.jpg']"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":52},"id":"2Kmwi7p8TtbE","executionInfo":{"status":"ok","timestamp":1617303192303,"user_tz":180,"elapsed":16011,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"1c00902f-945f-44f8-bb07-f0e94ed05d3d"},"source":["X_train[1]"],"execution_count":23,"outputs":[{"output_type":"execute_result","data":{"application/vnd.google.colaboratory.intrinsic+json":{"type":"string"},"text/plain":["'/content/drive/.shortcut-targets-by-id/17pVG9Sy8XzdWBm7-KrdDnpAmGyZRy0Vc/images_scaled/0613/5e26b456cdda49c1ba8d70069008d833.jpg'"]},"metadata":{"tags":[]},"execution_count":23}]},{"cell_type":"markdown","metadata":{"id":"xp_XtVrFUZrn"},"source":["**For simplicity, let's encode our target labels into one-hot encoded labels using preprocessing.LabelBinarizer().**"]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"h7wcVeVh5tR_","executionInfo":{"status":"ok","timestamp":1617312780289,"user_tz":180,"elapsed":1392,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"6484ad5e-5fbc-453f-c1f4-01459f095fca"},"source":["from sklearn import preprocessing\n","lb = preprocessing.LabelBinarizer()\n","lb.fit(y_train)\n","lb.fit(y_val)"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["LabelBinarizer(neg_label=0, pos_label=1, sparse_output=False)"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"4mH3M4RU5tO1","executionInfo":{"status":"ok","timestamp":1617312783320,"user_tz":180,"elapsed":1685,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["y_train_bin = lb.transform(y_train)\n","y_val_bin = lb.transform(y_val)\n","y_test_bin = lb.transform(y_test)"],"execution_count":17,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"iIvcQkd8XgJ0"},"source":["**Model Inception ResNet V2 preferes images with shape of (299, 299, 3).**"]},{"cell_type":"code","metadata":{"id":"TfMhFveR5tM8","executionInfo":{"status":"ok","timestamp":1617312794165,"user_tz":180,"elapsed":932,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["IMG_SIZE = 299 # Specify height and width of image to match the input format of the model\n","CHANNELS = 3 # Keep RGB color channels to match the input format of the model\n","N_CLASSES = len(lb.classes_)"],"execution_count":18,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2rb64cOWX7lW"},"source":["**Create a function that normalize and resize images inputs to the fixed shape required by the model.**"]},{"cell_type":"code","metadata":{"id":"pZ3mrIjZ5tK7","executionInfo":{"status":"ok","timestamp":1617312797718,"user_tz":180,"elapsed":1387,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["def parse_img_label(filename, label):\n","    \n","    \n","    # Read an image from a file\n","    image_string = tf.io.read_file(filename)\n","\n","    # Decode it into a dense vector\n","    image_decoded = tf.image.decode_jpeg(image_string, channels=CHANNELS)\n","\n","    # Resize it to fixed shape\n","    image_resized = tf.image.resize(image_decoded, [IMG_SIZE, IMG_SIZE])\n","\n","    # Normalize it from [0, 255] to [0.0, 1.0]\n","    image_normalized = image_resized / 255.0\n","    \n","    return image_normalized, label"],"execution_count":19,"outputs":[]},{"cell_type":"code","metadata":{"id":"6vTgUzHL5tIv","executionInfo":{"status":"ok","timestamp":1617312801742,"user_tz":180,"elapsed":929,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["BATCH_SIZE = 512 # Big enough to measure an F1-score\n","AUTOTUNE = tf.data.experimental.AUTOTUNE # Adapt preprocessing and prefetching dynamically\n","SHUFFLE_BUFFER_SIZE = 512 # Shuffle the training data by a chunck of 512 observations"],"execution_count":20,"outputs":[]},{"cell_type":"code","metadata":{"id":"c2nsd0mq5tGg","executionInfo":{"status":"ok","timestamp":1617312806068,"user_tz":180,"elapsed":1090,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["def gen_dataset(filenames, labels, is_training=True):\n","    \n","    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))\n","    dataset = dataset.map(parse_img_label, num_parallel_calls=AUTOTUNE)\n","    \n","    if is_training == True:\n","        # This is a small dataset, only load it once, and keep it in memory.\n","        dataset = dataset.cache()\n","        # Shuffle the data each buffer size\n","        dataset = dataset.shuffle(buffer_size=SHUFFLE_BUFFER_SIZE)\n","        \n","    dataset = dataset.batch(BATCH_SIZE)\n","    dataset = dataset.prefetch(buffer_size=AUTOTUNE)\n","    \n","    return dataset"],"execution_count":21,"outputs":[]},{"cell_type":"code","metadata":{"id":"pvbyQ_Mo5tEa","executionInfo":{"status":"ok","timestamp":1617312811141,"user_tz":180,"elapsed":1441,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["train_ds = gen_dataset(X_train, y_train_bin)\n","val_ds = gen_dataset(X_val, y_val_bin)\n","test_ds = gen_dataset(X_test, y_test_bin)"],"execution_count":22,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TIfSK9YB7HZk","executionInfo":{"status":"ok","timestamp":1617303195754,"user_tz":180,"elapsed":19428,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"731b40a4-5b5b-4235-e8b8-73f013faa0d6"},"source":["for f, l in train_ds.take(1):\n","    print(\"Shape of features array:\", f.numpy().shape)\n","    print(\"Shape of labels array:\", l.numpy().shape)"],"execution_count":31,"outputs":[{"output_type":"stream","text":["Shape of features array: (512, 299, 299, 3)\n","Shape of labels array: (512, 453)\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"shc6gxhRYLrc","executionInfo":{"status":"ok","timestamp":1617312814715,"user_tz":180,"elapsed":925,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["def macro_f1(y, y_hat, thresh=0.5): \n","    y_pred = tf.cast(tf.greater(y_hat, thresh), tf.float32)\n","    tp = tf.cast(tf.math.count_nonzero(y_pred * y, axis=0), tf.float32)\n","    fp = tf.cast(tf.math.count_nonzero(y_pred * (1 - y), axis=0), tf.float32)\n","    fn = tf.cast(tf.math.count_nonzero((1 - y_pred) * y, axis=0), tf.float32)\n","    f1 = 2*tp / (2*tp + fn + fp + 1e-16)\n","    macro_f1 = tf.reduce_mean(f1)\n","    return macro_f1"],"execution_count":23,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"7HOIYFtSTc30"},"source":["# **Big Transfer (BiT) is a recipe for pre-training image classification models on large supervised datasets**"]},{"cell_type":"code","metadata":{"id":"phzgq7MxQpi3","executionInfo":{"status":"ok","timestamp":1617312159682,"user_tz":180,"elapsed":105533,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["feature_extractor_url = \"https://tfhub.dev/google/bit/s-r152x4/1\"\n","feature_extractor_layer = hub.KerasLayer(feature_extractor_url, \n","                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))"],"execution_count":27,"outputs":[]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"icCCmFxQQqte","executionInfo":{"status":"ok","timestamp":1617312175926,"user_tz":180,"elapsed":2672,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"34c50fc2-9c2e-4d0d-b245-c5ab8e17a072"},"source":["model = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    layers.Dense(N_CLASSES, activation='softmax', name='output')\n","])\n","\n","model.summary()"],"execution_count":28,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","keras_layer (KerasLayer)     (None, 8192)              928340224 \n","_________________________________________________________________\n","output (Dense)               (None, 453)               3711429   \n","=================================================================\n","Total params: 932,051,653\n","Trainable params: 3,711,429\n","Non-trainable params: 928,340,224\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/","height":547},"id":"vtI9ADnfQqo_","executionInfo":{"status":"error","timestamp":1617312399749,"user_tz":180,"elapsed":217736,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"4fc229d3-feb7-4f14-c277-a6026d8aabaf"},"source":["batch_size = 128\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n","    loss=tf.keras.metrics.binary_crossentropy,\n","    metrics=[macro_f1, 'accuracy', tf.keras.metrics.TopKCategoricalAccuracy()])    # Default is k = 5\n","    \n","history = model.fit(train_ds, epochs=40,batch_size = batch_size, validation_data = val_ds,\n","                            validation_batch_size = batch_size)"],"execution_count":29,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n"],"name":"stdout"},{"output_type":"error","ename":"ResourceExhaustedError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mResourceExhaustedError\u001b[0m                    Traceback (most recent call last)","\u001b[0;32m<ipython-input-29-7206e64deac7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m history = model.fit(train_ds, epochs=40,batch_size = batch_size, validation_data = val_ds,\n\u001b[0;32m----> 8\u001b[0;31m                             validation_batch_size = batch_size)\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1098\u001b[0m                 _r=1):\n\u001b[1;32m   1099\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1100\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1101\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1102\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    886\u001b[0m         \u001b[0;31m# Lifting succeeded, so variables are initialized and we can run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    887\u001b[0m         \u001b[0;31m# stateless function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 888\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    889\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    890\u001b[0m       \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfiltered_flat_args\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2941\u001b[0m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[0;32m-> 2943\u001b[0;31m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n\u001b[0m\u001b[1;32m   2944\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2945\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1917\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1918\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1919\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1920\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1921\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    558\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    559\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 560\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    561\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    562\u001b[0m           outputs = execute.execute_with_cancellation(\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mResourceExhaustedError\u001b[0m:  OOM when allocating tensor with shape[512,256,112,112] and type float on /job:localhost/replica:0/task:0/device:GPU:0 by allocator GPU_0_bfc\n\t [[{{node sequential/keras_layer/StatefulPartitionedCall/StatefulPartitionedCall/StatefulPartitionedCall/root_block/StatefulPartitionedCall/standardized_conv2d/Conv2D}}]]\nHint: If you want to see a list of allocated tensors when OOM happens, add report_tensor_allocations_upon_oom to RunOptions for current allocation info.\n [Op:__inference_train_function_239032]\n\nFunction call stack:\ntrain_function\n"]}]},{"cell_type":"code","metadata":{"id":"57zHeuh_Qqmm"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"uMXwKOBcQqlH"},"source":["top5_acc = history.history['top_k_categorical_accuracy']\n","val_top5_acc = history.history['val_top_k_categorical_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, top5_acc, label='Training top 5 accuracy')\n","plt.plot(epochs_range, val_top5_acc, label='Validation top 5 accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation top 5 accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"O53MnHNxQqjg"},"source":["mf1 = history.history['macro_f1']\n","val_mf1 = history.history['val_macro_f1']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, mf1, label='Training macro f1')\n","plt.plot(epochs_range, val_mf1, label='Validation macro f1')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation macro f1')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"a59OejDHQqgt"},"source":["Result = model.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Z-Wl-u9cQqeR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ScACQeQAQqb4"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Y47SG1d-UWhR"},"source":["# **Inception ResNet V2**"]},{"cell_type":"code","metadata":{"id":"ydlqRIRTU36h","executionInfo":{"status":"ok","timestamp":1617312835074,"user_tz":180,"elapsed":11256,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}}},"source":["feature_extractor_url = \"https://tfhub.dev/google/imagenet/inception_resnet_v2/feature_vector/4\"\n","feature_extractor_layer = hub.KerasLayer(feature_extractor_url, trainable=False, \n","                                         input_shape=(IMG_SIZE,IMG_SIZE,CHANNELS))"],"execution_count":24,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xjaSS8Ygg97u"},"source":["### **Model1: no extra layers**"]},{"cell_type":"code","metadata":{"id":"RZQQnVJEU39J","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1617312838865,"user_tz":180,"elapsed":1896,"user":{"displayName":"Felipe A. Gomes Ferreira","photoUrl":"","userId":"09095471911889500468"}},"outputId":"e8cf5885-ed21-449f-9cd5-0215454157e2"},"source":["model = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    layers.Dense(N_CLASSES, activation='softmax', name='output')\n","])\n","\n","model.summary()"],"execution_count":25,"outputs":[{"output_type":"stream","text":["Model: \"sequential\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","keras_layer (KerasLayer)     (None, 1536)              54336736  \n","_________________________________________________________________\n","output (Dense)               (None, 453)               696261    \n","=================================================================\n","Total params: 55,032,997\n","Trainable params: 696,261\n","Non-trainable params: 54,336,736\n","_________________________________________________________________\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"-EOnzRHPU4Cy","colab":{"base_uri":"https://localhost:8080/"},"outputId":"1f7d3caa-0828-4a8f-e1ff-ac625481d673"},"source":["batch_size = 128\n","model.compile(\n","    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n","    loss=tf.keras.metrics.binary_crossentropy,\n","    metrics=[macro_f1, 'accuracy', tf.keras.metrics.TopKCategoricalAccuracy()])    # Default is k = 5\n","    \n","history = model.fit(train_ds, epochs=40,batch_size = batch_size, validation_data = val_ds,\n","                            validation_batch_size = batch_size)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Epoch 1/40\n","39/52 [=====================>........] - ETA: 18:23 - loss: 0.3215 - macro_f1: 0.0000e+00 - accuracy: 0.0024 - top_k_categorical_accuracy: 0.0116"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8p73n7cKhSwa"},"source":["mf1 = history.history['macro_f1']\n","val_mf1 = history.history['val_macro_f1']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, mf1, label='Training macro f1')\n","plt.plot(epochs_range, val_mf1, label='Validation macro f1')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation macro f1')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QmfK5HWchSsY"},"source":["acc = history.history['accuracy']\n","val_acc = history.history['val_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b99plLc9w_zO"},"source":["top5_acc = history.history['top_k_categorical_accuracy']\n","val_top5_acc = history.history['val_top_k_categorical_accuracy']\n","\n","loss = history.history['loss']\n","val_loss = history.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, top5_acc, label='Training top 5 accuracy')\n","plt.plot(epochs_range, val_top5_acc, label='Validation top 5 accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation top 5 accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"k1gDmAidhSqc"},"source":["Result = model.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"B7-KG-ZwhSnR"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ul6m9zSnhSkG"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5Xv4z3BT5c7W"},"source":["## **Model2 = Model1 + Dense(1024, relu) + Dropout(0.2) + Dense(512, relu)**"]},{"cell_type":"code","metadata":{"id":"tvyMKyySU4Fk"},"source":["model2 = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    layers.Dense(1024, activation='relu', name='hidden_layer1'),\n","    layers.Dropout(0.2),\n","    layers.Dense(512, activation='relu', name='hidden_layer2'),\n","    layers.Dense(N_CLASSES, activation='softmax', name='output')\n","])\n","\n","model2.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ornmKpZw6PhT"},"source":["model2.compile(\n","    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n","    loss=tf.keras.metrics.binary_crossentropy,\n","    metrics=[macro_f1, 'accuracy'])\n","    \n","history2 = model2.fit(train_ds, epochs=60,batch_size = 128,\n","                            validation_data=create_dataset(X_val, y_val_bin))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1g0_vl_8U4Kr"},"source":["mf1 = history2.history['macro_f1']\n","val_mf1 = history2.history['val_macro_f1']\n","\n","loss = history2.history['loss']\n","val_loss = history2.history['val_loss']\n","\n","epochs_range = range(60)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, mf1, label='Training macro f1')\n","plt.plot(epochs_range, val_mf1, label='Validation macro f1')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation macro f1')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"bWQduuEWU4OO"},"source":["acc = history2.history['accuracy']\n","val_acc = history2.history['val_accuracy']\n","\n","loss = history2.history['loss']\n","val_loss = history2.history['val_loss']\n","\n","epochs_range = range(60)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kkMeBzuNigXm"},"source":["Result2 = model2.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ieNPsNzhTZs2"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EyXp63mPTZpk"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jcM7lqHWWZwV"},"source":["## **Model3 = Model2 + More Dense Layers with Dropouts**"]},{"cell_type":"code","metadata":{"id":"7vs0iLilTZmm"},"source":["model3 = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    layers.Dense(4096, activation='relu', name='hidden_layer1'),\n","    layers.Dropout(0.25),\n","    layers.Dense(2048, activation='relu', name='hidden_layer2'),\n","    layers.Dropout(0.25),\n","    layers.Dense(1024, activation='relu', name='hidden_layer3'),\n","    layers.Dropout(0.25),\n","    layers.Dense(N_CLASSES, activation='softmax', name='output')\n","])\n","\n","model3.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BtrA62qMTZj-"},"source":["model3.compile(\n","    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n","    loss=tf.keras.metrics.binary_crossentropy,\n","    metrics=[macro_f1, 'accuracy'])\n","    \n","history3 = model3.fit(train_ds, epochs=60,batch_size = 128,\n","                            validation_data=create_dataset(X_val, y_val_bin))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8MI431xTZcV"},"source":["mf1 = history3.history['macro_f1']\n","val_mf1 = history3.history['val_macro_f1']\n","\n","loss = history3.history['loss']\n","val_loss = history3.history['val_loss']\n","\n","epochs_range = range(60)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, mf1, label='Training macro f1')\n","plt.plot(epochs_range, val_mf1, label='Validation macro f1')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation macro f1')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"2R3SMhmlV8Kc"},"source":["acc = history3.history['accuracy']\n","val_acc = history3.history['val_accuracy']\n","\n","loss = history3.history['loss']\n","val_loss = history3.history['val_loss']\n","\n","epochs_range = range(60)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BraCBC69WKad"},"source":["Result3 = model3.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BMgZr1IewXmF"},"source":["Result3"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"zeUIE-Ajyhrh"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5U8twnc_yhnb"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"hmm7ZxGwy4yR"},"source":["### **Model4 = Model3 with top5 accuracy classification**"]},{"cell_type":"code","metadata":{"id":"Bpa4o0nRyhjf"},"source":["model4 = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    layers.Dense(4096, activation='relu', name='hidden_layer1'),\n","    layers.Dropout(0.25),\n","    layers.Dense(2048, activation='relu', name='hidden_layer2'),\n","    layers.Dropout(0.25),\n","    layers.Dense(1024, activation='relu', name='hidden_layer3'),\n","    layers.Dropout(0.25),\n","    layers.Dense(N_CLASSES, activation='softmax', name='output')\n","])\n","\n","model4.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"R6nlta9wyhhl"},"source":["model4.compile(\n","    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n","    loss=tf.keras.metrics.binary_crossentropy,\n","    metrics=[macro_f1, 'accuracy', tf.keras.metrics.TopKCategoricalAccuracy()])\n","    \n","history4 = model4.fit(train_ds, epochs=60,batch_size = 128,\n","                            validation_data=create_dataset(X_val, y_val_bin))\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dFIcqrRmyhe-"},"source":["mf1 = history4.history['macro_f1']\n","val_mf1 = history4.history['val_macro_f1']\n","\n","loss = history4.history['loss']\n","val_loss = history4.history['val_loss']\n","\n","epochs_range = range(60)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, mf1, label='Training macro f1')\n","plt.plot(epochs_range, val_mf1, label='Validation macro f1')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation macro f1')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rBiNg9q4LSzy"},"source":["top5_acc = history4.history['top_k_categorical_accuracy']\n","val_top5_acc = history4.history['val_top_k_categorical_accuracy']\n","\n","loss = history4.history['loss']\n","val_loss = history4.history['val_loss']\n","\n","epochs_range = range(60)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, top5_acc, label='Training top 5 accuracy')\n","plt.plot(epochs_range, val_top5_acc, label='Validation top 5 accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation top 5 accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rTWh08eoyhco"},"source":["acc = history4.history['accuracy']\n","val_acc = history4.history['val_accuracy']\n","\n","loss = history4.history['loss']\n","val_loss = history4.history['val_loss']\n","\n","epochs_range = range(60)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vxAHmHo1y1QA"},"source":["Result4 = model4.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"qLHImscRKayV"},"source":["Result4"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"tkU-8M5hVjAe"},"source":["# Number of correct and incorrect predictions of the model\n","\n","predictions = model4.predict(test_ds)\n","\n","Incorrect = (np.argmax(predictions) !=  np.argmax(y_test_bin)).sum()\n","Correct = (np.argmax(predictions) ==  np.argmax(y_test_bin)).sum()\n","print('Number of correct predictions:', Correct)\n","print('Number of incorrect predictions:', Incorrect)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WgIVDPWjSAPO"},"source":["# Number of correct and incorrect predictions of the model\n","\n","predictions = model4.predict(test_ds)\n","\n","Incorrect = (np.argmax(predictions, axis=1) !=  np.argmax(y_test_bin,axis=1)).sum()\n","Correct = (np.argmax(predictions, axis=1) ==  np.argmax(y_test_bin,axis=1)).sum()\n","print('Number of correct predictions:', Correct)\n","print('Number of incorrect predictions:', Incorrect)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"kWCG_aHoSBe5"},"source":["test_ds"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9TT7Du6CSBa2"},"source":["X_test"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"cnG3DP__SBY7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TjnzommfSBVz"},"source":["4096*2*2*2*2"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8scBfuTWSBTD"},"source":["model5 = tf.keras.Sequential([\n","    feature_extractor_layer,\n","    layers.Dense(16384, activation='relu', name='hidden_layer3'),\n","    layers.Dropout(0.25),\n","    layers.Dense(8192, activation='relu', name='hidden_layer4'),\n","    layers.Dropout(0.25),\n","    layers.Dense(4096, activation='relu', name='hidden_layer5'),\n","    layers.Dropout(0.25),\n","    layers.Dense(2048, activation='relu', name='hidden_layer6'),\n","    layers.Dropout(0.25),\n","    layers.Dense(1024, activation='relu', name='hidden_layer7'),\n","    layers.Dropout(0.25),\n","    layers.Dense(N_CLASSES, activation='softmax', name='output')\n","])\n","\n","model5.summary()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ymiq5nhcgx9o"},"source":["model5.compile(\n","    optimizer=tf.keras.optimizers.Adam(lr=5e-4),\n","    loss=tf.keras.metrics.binary_crossentropy,\n","    metrics=[macro_f1, 'accuracy', tf.keras.metrics.TopKCategoricalAccuracy()])\n","    \n","history5 = model5.fit(train_ds, epochs=40,batch_size = 256,\n","                            validation_data=val_ds)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5vVUpQB1gx6q"},"source":["mf1 = history5.history['macro_f1']\n","val_mf1 = history5.history['val_macro_f1']\n","\n","loss = history5.history['loss']\n","val_loss = history5.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, mf1, label='Training macro f1')\n","plt.plot(epochs_range, val_mf1, label='Validation macro f1')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation macro f1')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0lvZ-zwegx5S"},"source":["top5_acc = history5.history['top_k_categorical_accuracy']\n","val_top5_acc = history5.history['val_top_k_categorical_accuracy']\n","\n","loss = history5.history['loss']\n","val_loss = history5.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, top5_acc, label='Training top 5 accuracy')\n","plt.plot(epochs_range, val_top5_acc, label='Validation top 5 accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation top 5 accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"F2Pi6kregx1g"},"source":["acc = history5.history['accuracy']\n","val_acc = history5.history['val_accuracy']\n","\n","loss = history5.history['loss']\n","val_loss = history5.history['val_loss']\n","\n","epochs_range = range(40)\n","\n","plt.figure(figsize=(8, 8))\n","plt.subplot(1, 2, 1)\n","plt.plot(epochs_range, acc, label='Training accuracy')\n","plt.plot(epochs_range, val_acc, label='Validation accuracy')\n","plt.legend(loc='lower right')\n","plt.title('Training and Validation accuracies')\n","\n","plt.subplot(1, 2, 2)\n","plt.plot(epochs_range, loss, label='Training Loss')\n","plt.plot(epochs_range, val_loss, label='Validation Loss')\n","plt.legend(loc='upper right')\n","plt.title('Training and Validation Loss')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EfVNEg5dgxzy"},"source":["Result5 = model5.evaluate(test_ds)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NW1psIV-gxwr"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"78x0XUL7SAMV"},"source":[""],"execution_count":null,"outputs":[]}]}